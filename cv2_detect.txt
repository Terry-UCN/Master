import cv2
import torch
import torchvision.transforms as transforms
from torchvision import models
from PIL import Image

# === 設定裝置 ===
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === 建立與載入模型 ===
model = models.efficientnet_b0(pretrained=False)
model.classifier[1] = torch.nn.Linear(model.classifier[1].in_features, 5)
model.load_state_dict(torch.load("best_trash_model.pth", map_location=device))
model = model.to(device)
model.eval()

# === 類別名稱 ===
classes = ['cardboard', 'glass', 'metal', 'paper', 'plastic']

# === 預處理流程（與訓練一致）===
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406],
                         [0.229, 0.224, 0.225])
])

# === 開啟 webcam ===
cap = cv2.VideoCapture("CHANGE TO YOUR IP CAM ACCESS/video")
  # "http://..... :4747/video"
  # 4747 為預設的第一個攝像頭
  # 

print("📷 開始即時辨識（按下 q 鍵可退出）")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    # 擷取畫面中央區域作為目標框（可依實際調整）
    h, w, _ = frame.shape
    crop_size = 224
    center_x, center_y = w // 2, h // 2
    x1, y1 = center_x - crop_size // 2, center_y - crop_size // 2
    x2, y2 = center_x + crop_size // 2, center_y + crop_size // 2
    cropped = frame[y1:y2, x1:x2]

    # 預處理
    image = Image.fromarray(cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB))
    input_tensor = transform(image).unsqueeze(0).to(device)

    # 推論
    with torch.no_grad():
        outputs = model(input_tensor)
        pred_idx = outputs.argmax(dim=1).item()
        pred_label = classes[pred_idx]

    # 顯示結果與畫框
    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 255), 2)
    cv2.putText(frame, f'Prediction: {pred_label}', (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

    cv2.imshow("Real-Time Garbage Classifier", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
